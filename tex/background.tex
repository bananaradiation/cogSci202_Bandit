\section{Background}
\label{background}

\subsection{Related Work}
\todo[inline]{Shuannan's work}
The stochastic multi-armed bandit problem is an important model for studying the exploration-exploitation trade-off in reinforcement learning.The goal of the decision-maker here is to obtain the maximum number of rewards over a number of trials. This report presents an empirical study of the some popular 2-armed bandit algorithms. Our work is motivated from the paper "Psychological models of human and optimal performance in bandit problems." The paper presents a variety of existing heuristic algorithms for finite horizon multi-arm bandit problems. It then builds on the idea of latent state modeling and presents a new model for the decision-making process in the bandit problem. It uses a Bayesian model in which how people balance exploration with exploitation depends on their assumptions about the distribution of reward rates. 

 